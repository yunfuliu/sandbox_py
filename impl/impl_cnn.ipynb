{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements the cnn with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# run session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_image = 28 # image size\n",
    "dim_fe = size_image*size_image # dim of feature \n",
    "n_class = 10 # number of classes\n",
    "size_batch = 50 # batch size\n",
    "\n",
    "class param_conv1:\n",
    "    patch_size = 5\n",
    "    n_input_channels = 1\n",
    "    n_output_channels = 32\n",
    "class param_conv2:\n",
    "    patch_size = 5\n",
    "    n_input_channels = 32\n",
    "    n_output_channels = 64    \n",
    "class param_fc1:\n",
    "    image_size = 7\n",
    "    n_neurons = 1024\n",
    "    n_output_channels = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's shape: (?, 784)\n",
      "y_'s shape: (?, 10)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None,dim_fe], name='x')\n",
    "y_ = tf.placeholder(dtype=tf.float32, shape=[None,n_class], name='y_')\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "print 'x\\'s shape:', x.get_shape()\n",
    "print 'y_\\'s shape:', y_.get_shape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define layers\n",
    "define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables\n",
    "def weight_variable(shape):    \n",
    "    return tf.Variable(tf.truncated_normal(shape=shape,mean=0.,stddev=0.1))\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(value=0.1,dtype=tf.float32,shape=shape))\n",
    "# operations\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1,1,1,1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(value=x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define first conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_conv1's shape: (5, 5, 1, 32)\n",
      "b_conv1's shape: (32,)\n",
      "x's shape: (?, 784)\n",
      "x_image's shape: (?, 28, 28, 1)\n",
      "h_conv1's shape: (?, 28, 28, 32)\n",
      "h_pool1's shape: (?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "W_conv1 = weight_variable(\n",
    "    shape=[param_conv1.patch_size, param_conv1.patch_size, \n",
    "           param_conv1.n_input_channels, param_conv1.n_output_channels])\n",
    "b_conv1 = bias_variable(\n",
    "    shape=[param_conv1.n_output_channels])\n",
    "print 'W_conv1\\'s shape:', W_conv1.get_shape()\n",
    "print 'b_conv1\\'s shape:', b_conv1.get_shape()\n",
    "\n",
    "# reshape input image\n",
    "print 'x\\'s shape:', x.get_shape()\n",
    "x_image = tf.reshape(tensor=x,shape=[-1,size_image,size_image,1])\n",
    "print 'x_image\\'s shape:', x_image.get_shape()\n",
    "\n",
    "# outputs\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "print 'h_conv1\\'s shape:', h_conv1.get_shape()\n",
    "print 'h_pool1\\'s shape:', h_pool1.get_shape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define second conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_conv2's shape: (5, 5, 32, 64)\n",
      "b_conv2's shape: (64,)\n",
      "h_conv2's shape: (?, 14, 14, 64)\n",
      "h_pool2's shape: (?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "W_conv2 = weight_variable(\n",
    "    shape=[param_conv2.patch_size, param_conv2.patch_size, \n",
    "           param_conv2.n_input_channels, param_conv2.n_output_channels])\n",
    "b_conv2 = bias_variable(\n",
    "    shape=[param_conv2.n_output_channels])\n",
    "print 'W_conv2\\'s shape:', W_conv2.get_shape()\n",
    "print 'b_conv2\\'s shape:', b_conv2.get_shape()\n",
    "\n",
    "# outputs\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "print 'h_conv2\\'s shape:', h_conv2.get_shape()\n",
    "print 'h_pool2\\'s shape:', h_pool2.get_shape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define fc1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136\n",
      "W_fc1's shape: (3136, 1024)\n",
      "b_fc1's shape: (1024,)\n",
      "h_pool2_flat's shape: (?, 3136)\n",
      "h_fc1's shape: (?, 1024)\n"
     ]
    }
   ],
   "source": [
    "n_weights = int(h_pool2.get_shape()[1]*h_pool2.get_shape()[2]*h_pool2.get_shape()[3])\n",
    "print n_weights\n",
    "W_fc1 = weight_variable([n_weights,param_fc1.n_neurons])\n",
    "b_fc1 = bias_variable([param_fc1.n_neurons])\n",
    "print 'W_fc1\\'s shape:', W_fc1.get_shape()\n",
    "print 'b_fc1\\'s shape:', b_fc1.get_shape()\n",
    "\n",
    "# flat h_pool2\n",
    "h_pool2_flat = tf.reshape(h_pool2,shape=[-1,n_weights])\n",
    "print 'h_pool2_flat\\'s shape:', h_pool2_flat.get_shape()\n",
    "\n",
    "# get h_fc1\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "print 'h_fc1\\'s shape:', h_fc1.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_fc1_drop's shape: (?, 1024)\n"
     ]
    }
   ],
   "source": [
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob=keep_prob)\n",
    "print 'h_fc1_drop\\'s shape:', h_fc1_drop.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_fc2's shape: (1024, 10)\n",
      "b_fc2's shape: (10,)\n",
      "y_conv's shape: (?, 10)\n"
     ]
    }
   ],
   "source": [
    "W_fc2 = weight_variable([int(h_fc1.get_shape()[1]),n_class])\n",
    "b_fc2 = bias_variable([n_class])\n",
    "print 'W_fc2\\'s shape:', W_fc2.get_shape()\n",
    "print 'b_fc2\\'s shape:', b_fc2.get_shape()\n",
    "\n",
    "# # flat h_pool2\n",
    "# h_pool2_flat = tf.reshape(h_pool2,shape=[-1,n_weights])\n",
    "# print 'h_pool2_flat\\'s shape:', h_pool2_flat.get_shape()\n",
    "\n",
    "# get h_fc2\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "print 'y_conv\\'s shape:', y_conv.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    input_tensor=-tf.reduce_sum(input_tensor=y_*tf.log(y_conv), reduction_indices=[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv,dimension=1), tf.argmax(y_,dimension=1))\n",
    "accuracy = tf.reduce_mean(input_tensor=tf.cast(correct_prediction, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.18\n",
      "50 0.68\n",
      "100 0.78\n",
      "150 0.92\n",
      "200 0.94\n",
      "250 0.92\n",
      "300 0.86\n",
      "350 0.92\n",
      "400 0.98\n",
      "450 0.9\n",
      "500 0.94\n",
      "550 0.96\n",
      "600 0.98\n",
      "650 0.96\n",
      "700 0.96\n",
      "750 0.94\n",
      "800 0.96\n",
      "850 0.98\n",
      "900 0.96\n",
      "950 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f40b6098f90>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f40b62bdad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss=cross_entropy)\n",
    "\n",
    "# initialize\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# training\n",
    "x_axis = []\n",
    "err_train = []\n",
    "err_test = []\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    # draw error line\n",
    "    if i%50 == 0:\n",
    "        x_axis.append(i)\n",
    "        train_accu = accuracy.eval(feed_dict={x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "#         test_accu = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "        err_train.append(train_accu)\n",
    "#         err_test.append(test_accu)\n",
    "        print i, train_accu\n",
    "    \n",
    "# plot\n",
    "plt.plot(x_axis, err_train)\n",
    "# plt.plot(x_axis, err_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4339b97e8e60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
